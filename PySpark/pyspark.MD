# Big Data

Dataset too complex fot standard data processing. Definition is vague and varied.

## Introduction of Big Data

### 3 V's of Big Data

Volume : Size of the Data

Variety : Types of Data

Velocity: Speed of Data

### Terminology

Clustered Computing : Collection of resources of multiple machines.

Parallel Computing : Simultaneous computation.

Distributed Computing: Nodes that run in parallel.

Batch Processing: Breaking a large job into small batches and executing them independently.

Real-time Processing: Processing Data in Real-time.

## Introduction to PySpark

PySpark is the Python API for Apache Spark. Apache Spark is written in Scala. PySpark API is similar to Pandas and Scikit-learn.

Spark shell is the interactive environment for running Spark jobs. It is helpful for fast prototyping and interacting with data on disk or in memory. Spark shell is available for Scala, Python and R.

### Features of Apache Spark

- Distributed cluster computer framework.
- Efficient in-memory computation.
- Support for Java, Scala, Python, R and SQL.

### Spark Context

